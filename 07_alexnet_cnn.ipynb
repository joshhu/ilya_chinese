{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 論文 7：使用深度卷積神經網路進行 ImageNet 分類\n",
    "## Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton (2012)\n",
    "\n",
    "### AlexNet：引發深度學習革命的 CNN\n",
    "\n",
    "AlexNet 以 15.3% 的 top-5 錯誤率贏得 ImageNet 2012，大幅領先第二名（26.2%）。這篇論文重新點燃了對深度學習的興趣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import correlate2d\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷積層實作\n",
    "\n",
    "CNN 的核心建構元件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def conv2d(input_image, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    2D 卷積運算\n",
    "    \n",
    "    input_image: (H, W) 或 (C, H, W)\n",
    "    kernel: (out_channels, in_channels, kH, kW)\n",
    "    \"\"\"\n",
    "    if len(input_image.shape) == 2:\n",
    "        input_image = input_image[np.newaxis, :, :]\n",
    "    \n",
    "    in_channels, H, W = input_image.shape\n",
    "    out_channels, _, kH, kW = kernel.shape\n",
    "    \n",
    "    # 添加填充\n",
    "    if padding > 0:\n",
    "        input_padded = np.pad(input_image, \n",
    "                             ((0, 0), (padding, padding), (padding, padding)), \n",
    "                             mode='constant')\n",
    "    else:\n",
    "        input_padded = input_image\n",
    "    \n",
    "    # 輸出維度\n",
    "    out_H = (H + 2*padding - kH) // stride + 1\n",
    "    out_W = (W + 2*padding - kW) // stride + 1\n",
    "    \n",
    "    output = np.zeros((out_channels, out_H, out_W))\n",
    "    \n",
    "    # 執行卷積\n",
    "    for oc in range(out_channels):\n",
    "        for i in range(out_H):\n",
    "            for j in range(out_W):\n",
    "                h_start = i * stride\n",
    "                w_start = j * stride\n",
    "                \n",
    "                # 提取區塊\n",
    "                patch = input_padded[:, h_start:h_start+kH, w_start:w_start+kW]\n",
    "                \n",
    "                # 與核進行卷積\n",
    "                output[oc, i, j] = np.sum(patch * kernel[oc])\n",
    "    \n",
    "    return output\n",
    "\n",
    "def max_pool2d(input_image, pool_size=2, stride=2):\n",
    "    \"\"\"\n",
    "    最大池化運算\n",
    "    \"\"\"\n",
    "    C, H, W = input_image.shape\n",
    "    \n",
    "    out_H = (H - pool_size) // stride + 1\n",
    "    out_W = (W - pool_size) // stride + 1\n",
    "    \n",
    "    output = np.zeros((C, out_H, out_W))\n",
    "    \n",
    "    for c in range(C):\n",
    "        for i in range(out_H):\n",
    "            for j in range(out_W):\n",
    "                h_start = i * stride\n",
    "                w_start = j * stride\n",
    "                \n",
    "                pool_region = input_image[c, h_start:h_start+pool_size, \n",
    "                                         w_start:w_start+pool_size]\n",
    "                output[c, i, j] = np.max(pool_region)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# 測試卷積\n",
    "test_image = np.random.randn(1, 8, 8)\n",
    "test_kernel = np.random.randn(3, 1, 3, 3) * 0.1\n",
    "\n",
    "conv_output = conv2d(test_image, test_kernel, stride=1, padding=1)\n",
    "print(f\"輸入形狀：{test_image.shape}\")\n",
    "print(f\"核形狀：{test_kernel.shape}\")\n",
    "print(f\"卷積輸出形狀：{conv_output.shape}\")\n",
    "\n",
    "pooled = max_pool2d(conv_output, pool_size=2, stride=2)\n",
    "print(f\"最大池化後：{pooled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet 架構（簡化版）\n",
    "\n",
    "原始版：227x227x3 → 5 層卷積 → 3 層全連接 → 1000 類別\n",
    "\n",
    "我們簡化版用於 32x32 圖像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetSimplified:\n",
    "    def __init__(self, num_classes=10):\n",
    "        \"\"\"\n",
    "        用於 32x32 圖像的簡化 AlexNet（如 CIFAR-10）\n",
    "        \n",
    "        架構：\n",
    "        - Conv1: 3x3x3 -> 32 個濾波器\n",
    "        - MaxPool\n",
    "        - Conv2: 32 -> 64 個濾波器\n",
    "        - MaxPool\n",
    "        - Conv3: 64 -> 128 個濾波器\n",
    "        - 全連接層\n",
    "        \"\"\"\n",
    "        # 卷積層\n",
    "        self.conv1_filters = np.random.randn(32, 3, 3, 3) * 0.01\n",
    "        self.conv1_bias = np.zeros(32)\n",
    "        \n",
    "        self.conv2_filters = np.random.randn(64, 32, 3, 3) * 0.01\n",
    "        self.conv2_bias = np.zeros(64)\n",
    "        \n",
    "        self.conv3_filters = np.random.randn(128, 64, 3, 3) * 0.01\n",
    "        self.conv3_bias = np.zeros(128)\n",
    "        \n",
    "        # 全連接層（卷積後：128 * 4 * 4 = 2048）\n",
    "        self.fc1_weights = np.random.randn(2048, 512) * 0.01\n",
    "        self.fc1_bias = np.zeros(512)\n",
    "        \n",
    "        self.fc2_weights = np.random.randn(512, num_classes) * 0.01\n",
    "        self.fc2_bias = np.zeros(num_classes)\n",
    "    \n",
    "    def forward(self, x, use_dropout=False, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        前向傳遞\n",
    "        x: (3, 32, 32) 圖像\n",
    "        \"\"\"\n",
    "        # Conv1 + ReLU + MaxPool\n",
    "        conv1 = conv2d(x, self.conv1_filters, stride=1, padding=1)\n",
    "        conv1 += self.conv1_bias[:, np.newaxis, np.newaxis]\n",
    "        conv1 = relu(conv1)\n",
    "        pool1 = max_pool2d(conv1, pool_size=2, stride=2)  # 32 x 16 x 16\n",
    "        \n",
    "        # Conv2 + ReLU + MaxPool\n",
    "        conv2 = conv2d(pool1, self.conv2_filters, stride=1, padding=1)\n",
    "        conv2 += self.conv2_bias[:, np.newaxis, np.newaxis]\n",
    "        conv2 = relu(conv2)\n",
    "        pool2 = max_pool2d(conv2, pool_size=2, stride=2)  # 64 x 8 x 8\n",
    "        \n",
    "        # Conv3 + ReLU + MaxPool\n",
    "        conv3 = conv2d(pool2, self.conv3_filters, stride=1, padding=1)\n",
    "        conv3 += self.conv3_bias[:, np.newaxis, np.newaxis]\n",
    "        conv3 = relu(conv3)\n",
    "        pool3 = max_pool2d(conv3, pool_size=2, stride=2)  # 128 x 4 x 4\n",
    "        \n",
    "        # 展平\n",
    "        flattened = pool3.reshape(-1)\n",
    "        \n",
    "        # FC1 + ReLU + Dropout\n",
    "        fc1 = np.dot(flattened, self.fc1_weights) + self.fc1_bias\n",
    "        fc1 = relu(fc1)\n",
    "        \n",
    "        if use_dropout:\n",
    "            dropout_mask = (np.random.rand(*fc1.shape) > dropout_rate).astype(float)\n",
    "            fc1 = fc1 * dropout_mask / (1 - dropout_rate)\n",
    "        \n",
    "        # FC2（輸出）\n",
    "        output = np.dot(fc1, self.fc2_weights) + self.fc2_bias\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 建立模型\n",
    "alexnet = AlexNetSimplified(num_classes=10)\n",
    "print(\"AlexNet（簡化版）已建立\")\n",
    "\n",
    "# 測試前向傳遞\n",
    "test_img = np.random.randn(3, 32, 32)\n",
    "output = alexnet.forward(test_img)\n",
    "print(f\"輸入：(3, 32, 32)\")\n",
    "print(f\"輸出：{output.shape}（類別分數）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成合成圖像資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simple_images(num_samples=100, image_size=32):\n",
    "    \"\"\"\n",
    "    生成具有不同模式的簡單合成圖像\n",
    "    類別：\n",
    "    0: 水平條紋\n",
    "    1: 垂直條紋\n",
    "    2: 對角條紋\n",
    "    3: 棋盤格\n",
    "    4: 圓形\n",
    "    5: 方形\n",
    "    6: 十字\n",
    "    7: 三角形\n",
    "    8: 隨機雜訊\n",
    "    9: 純色\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        class_label = i % 10\n",
    "        img = np.zeros((3, image_size, image_size))\n",
    "        \n",
    "        if class_label == 0:  # 水平條紋\n",
    "            for row in range(0, image_size, 4):\n",
    "                img[:, row:row+2, :] = 1\n",
    "        \n",
    "        elif class_label == 1:  # 垂直條紋\n",
    "            for col in range(0, image_size, 4):\n",
    "                img[:, :, col:col+2] = 1\n",
    "        \n",
    "        elif class_label == 2:  # 對角線\n",
    "            for i in range(image_size):\n",
    "                if i < image_size:\n",
    "                    img[:, i, i] = 1\n",
    "                    if i+1 < image_size:\n",
    "                        img[:, i, i+1] = 1\n",
    "        \n",
    "        elif class_label == 3:  # 棋盤格\n",
    "            for i in range(0, image_size, 4):\n",
    "                for j in range(0, image_size, 4):\n",
    "                    if (i//4 + j//4) % 2 == 0:\n",
    "                        img[:, i:i+4, j:j+4] = 1\n",
    "        \n",
    "        elif class_label == 4:  # 圓形\n",
    "            center = image_size // 2\n",
    "            radius = image_size // 3\n",
    "            y_grid, x_grid = np.ogrid[:image_size, :image_size]\n",
    "            mask = (x_grid - center)**2 + (y_grid - center)**2 <= radius**2\n",
    "            img[:, mask] = 1\n",
    "        \n",
    "        elif class_label == 5:  # 方形\n",
    "            margin = image_size // 4\n",
    "            img[:, margin:-margin, margin:-margin] = 1\n",
    "        \n",
    "        elif class_label == 6:  # 十字\n",
    "            mid = image_size // 2\n",
    "            thickness = 3\n",
    "            img[:, mid-thickness:mid+thickness, :] = 1\n",
    "            img[:, :, mid-thickness:mid+thickness] = 1\n",
    "        \n",
    "        elif class_label == 7:  # 三角形\n",
    "            for i in range(image_size):\n",
    "                width = int((i / image_size) * image_size / 2)\n",
    "                start = image_size // 2 - width\n",
    "                end = image_size // 2 + width\n",
    "                img[:, i, start:end] = 1\n",
    "        \n",
    "        elif class_label == 8:  # 隨機雜訊\n",
    "            img = np.random.rand(3, image_size, image_size)\n",
    "        \n",
    "        else:  # 純色\n",
    "            img[:] = 0.7\n",
    "        \n",
    "        # 添加顏色變化\n",
    "        color = np.random.rand(3, 1, 1)\n",
    "        img = img * color\n",
    "        \n",
    "        # 添加雜訊\n",
    "        img += np.random.randn(3, image_size, image_size) * 0.1\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        X.append(img)\n",
    "        y.append(class_label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 生成資料集\n",
    "X_train, y_train = generate_simple_images(200)\n",
    "X_test, y_test = generate_simple_images(50)\n",
    "\n",
    "print(f\"訓練集：{X_train.shape}\")\n",
    "print(f\"測試集：{X_test.shape}\")\n",
    "\n",
    "# 視覺化樣本\n",
    "class_names = ['水平條紋', '垂直條紋', '對角線', '棋盤格', '圓形', \n",
    "               '方形', '十字', '三角形', '雜訊', '純色']\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    # 找到每個類別的第一個出現\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    img = X_train[idx].transpose(1, 2, 0)  # CHW -> HWC\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(class_names[i])\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('合成圖像資料集（10 個類別）', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料增強\n",
    "\n",
    "AlexNet 廣泛使用資料增強 - 這是一項關鍵創新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(img):\n",
    "    \"\"\"水平翻轉\"\"\"\n",
    "    if np.random.rand() > 0.5:\n",
    "        return img[:, :, ::-1].copy()\n",
    "    return img\n",
    "\n",
    "def random_crop(img, crop_size=28):\n",
    "    \"\"\"隨機裁剪\"\"\"\n",
    "    _, h, w = img.shape\n",
    "    top = np.random.randint(0, h - crop_size + 1)\n",
    "    left = np.random.randint(0, w - crop_size + 1)\n",
    "    \n",
    "    cropped = img[:, top:top+crop_size, left:left+crop_size]\n",
    "    \n",
    "    # 調整回原始大小\n",
    "    # 簡單最近鄰（用於示範）\n",
    "    scale_h = h / crop_size\n",
    "    scale_w = w / crop_size\n",
    "    \n",
    "    resized = np.zeros_like(img)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            src_i = min(int(i / scale_h), crop_size - 1)\n",
    "            src_j = min(int(j / scale_w), crop_size - 1)\n",
    "            resized[:, i, j] = cropped[:, src_i, src_j]\n",
    "    \n",
    "    return resized\n",
    "\n",
    "def add_noise(img, noise_level=0.05):\n",
    "    \"\"\"添加高斯雜訊\"\"\"\n",
    "    noise = np.random.randn(*img.shape) * noise_level\n",
    "    return np.clip(img + noise, 0, 1)\n",
    "\n",
    "def augment_image(img):\n",
    "    \"\"\"應用隨機增強\"\"\"\n",
    "    img = random_flip(img)\n",
    "    img = random_crop(img)\n",
    "    img = add_noise(img)\n",
    "    return img\n",
    "\n",
    "# 展示增強\n",
    "original = X_train[0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "axes[0, 0].imshow(original.transpose(1, 2, 0))\n",
    "axes[0, 0].set_title('原始')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "for i in range(1, 8):\n",
    "    augmented = augment_image(original.copy())\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axes[row, col].imshow(augmented.transpose(1, 2, 0))\n",
    "    axes[row, col].set_title(f'增強 {i}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('資料增強範例', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 視覺化學習到的濾波器\n",
    "\n",
    "AlexNet 的洞察之一：視覺化網路學到了什麼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化第一層濾波器\n",
    "filters = alexnet.conv1_filters  # 形狀：(32, 3, 3, 3)\n",
    "\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(min(32, len(axes))):\n",
    "    # 正規化濾波器以供視覺化\n",
    "    filt = filters[i].transpose(1, 2, 0)  # CHW -> HWC\n",
    "    filt = (filt - filt.min()) / (filt.max() - filt.min() + 1e-8)\n",
    "    \n",
    "    axes[i].imshow(filt)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'F{i}', fontsize=8)\n",
    "\n",
    "plt.suptitle('Conv1 濾波器（32 個濾波器，3x3，RGB）', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"這些濾波器學習檢測邊緣、顏色和簡單模式\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徵圖視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理一張圖像並視覺化特徵圖\n",
    "test_image = X_train[4]  # 圓形\n",
    "\n",
    "# 通過第一個卷積層前向傳遞\n",
    "conv1_output = conv2d(test_image, alexnet.conv1_filters, stride=1, padding=1)\n",
    "conv1_output += alexnet.conv1_bias[:, np.newaxis, np.newaxis]\n",
    "conv1_output = relu(conv1_output)\n",
    "\n",
    "# 視覺化\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# 原始圖像\n",
    "ax = plt.subplot(6, 6, 1)\n",
    "ax.imshow(test_image.transpose(1, 2, 0))\n",
    "ax.set_title('輸入圖像', fontsize=10)\n",
    "ax.axis('off')\n",
    "\n",
    "# 特徵圖\n",
    "for i in range(min(32, 35)):\n",
    "    ax = plt.subplot(6, 6, i+2)\n",
    "    ax.imshow(conv1_output[i], cmap='viridis')\n",
    "    ax.set_title(f'圖 {i}', fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Conv1 + ReLU 後的特徵圖', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"不同的特徵圖對圖像中的不同模式有反應\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "# 在幾張圖像上測試\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    idx = i * 5  # 每 5 張取一張\n",
    "    img = X_test[idx]\n",
    "    true_label = y_test[idx]\n",
    "    \n",
    "    # 前向傳遞\n",
    "    logits = alexnet.forward(img, use_dropout=False)\n",
    "    probs = softmax(logits)\n",
    "    pred_label = np.argmax(probs)\n",
    "    \n",
    "    # 顯示\n",
    "    axes[i].imshow(img.transpose(1, 2, 0))\n",
    "    axes[i].set_title(f'真實：{class_names[true_label]}\\n預測：{class_names[pred_label]}\\n信心：{probs[pred_label]:.2f}',\n",
    "                     fontsize=9)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('AlexNet 預測（未訓練）', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"注意：模型未訓練，所以預測是隨機的！\")\n",
    "print(\"訓練需要梯度下降，為了清晰起見我們簡化了。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 關鍵要點\n",
    "\n",
    "### AlexNet 創新（2012）：\n",
    "\n",
    "1. **ReLU 激活函數**：比 sigmoid/tanh 快得多\n",
    "   - 對正值無飽和\n",
    "   - 訓練更快（比 tanh 快 6 倍）\n",
    "\n",
    "2. **Dropout**：強大的正則化\n",
    "   - 防止過擬合\n",
    "   - 在全連接層使用（0.5 比率）\n",
    "\n",
    "3. **資料增強**：\n",
    "   - 隨機裁剪和翻轉\n",
    "   - 顏色抖動\n",
    "   - 人為增加資料集大小\n",
    "\n",
    "4. **GPU 訓練**：\n",
    "   - 使用 2 個 GTX 580 GPU\n",
    "   - 使深度網路訓練成為可能\n",
    "\n",
    "5. **局部響應正規化（LRN）**：\n",
    "   - 特徵圖之間的側向抑制\n",
    "   - 現在不太常用（批次正規化取代了它）\n",
    "\n",
    "### 架構：\n",
    "```\n",
    "輸入 (227x227x3)\n",
    "  ↓\n",
    "Conv1 (96 個濾波器, 11x11, 步幅 4) + ReLU + MaxPool\n",
    "  ↓\n",
    "Conv2 (256 個濾波器, 5x5) + ReLU + MaxPool\n",
    "  ↓\n",
    "Conv3 (384 個濾波器, 3x3) + ReLU\n",
    "  ↓\n",
    "Conv4 (384 個濾波器, 3x3) + ReLU\n",
    "  ↓\n",
    "Conv5 (256 個濾波器, 3x3) + ReLU + MaxPool\n",
    "  ↓\n",
    "FC6 (4096) + ReLU + Dropout\n",
    "  ↓\n",
    "FC7 (4096) + ReLU + Dropout\n",
    "  ↓\n",
    "FC8 (1000 類別) + Softmax\n",
    "```\n",
    "\n",
    "### 影響：\n",
    "- **贏得 ImageNet 2012**：15.3% top-5 錯誤率（vs 第二名 26.2%）\n",
    "- **重新點燃深度學習**：展示深度 + 資料 + 計算有效\n",
    "- **GPU 革命**：使 GPU 成為深度學習必需品\n",
    "- **啟發現代 CNN**：VGG、ResNet 等都建立在這些想法上\n",
    "\n",
    "### 為什麼有效：\n",
    "1. 深層架構（在 2012 年 8 層算深了！）\n",
    "2. 大型資料集（120 萬張 ImageNet 圖像）\n",
    "3. GPU 加速（使訓練可行）\n",
    "4. 智慧正則化（dropout + 資料增強）\n",
    "5. ReLU 激活函數（更快訓練）\n",
    "\n",
    "### 現代觀點：\n",
    "- AlexNet 現在被認為是「簡單」的\n",
    "- ResNets 有 100+ 層\n",
    "- 批次正規化取代了 LRN\n",
    "- 但核心理念仍然存在：\n",
    "  - 深層層級特徵\n",
    "  - 卷積用於空間結構\n",
    "  - 資料增強\n",
    "  - 正則化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
