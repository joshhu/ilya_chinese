{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è«–æ–‡ 8ï¼šé †åºå¾ˆé‡è¦ - åºåˆ—åˆ°åºåˆ—è™•ç†é›†åˆ\n",
    "\n",
    "**å¼•ç”¨**: Vinyals, O., Bengio, S., & Kudlur, M. (2016). Order Matters: Sequence to Sequence for Sets. In *International Conference on Learning Representations (ICLR)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¦‚è¿°èˆ‡æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "### è«–æ–‡æ‘˜è¦\n",
    "æœ¬è«–æ–‡è§£æ±ºäº†ä¸€å€‹æ ¹æœ¬æ€§çš„æŒ‘æˆ°ï¼š**å¦‚ä½•ç”¨ç‚ºåºåˆ—è¨­è¨ˆçš„ç¥ç¶“ç¶²è·¯ä¾†è™•ç†ç„¡åºé›†åˆï¼Ÿ**\n",
    "\n",
    "å‚³çµ±çš„ seq2seq æ¨¡å‹æ˜¯**é †åºæ•æ„Ÿ**çš„ - å®ƒå€‘å° `[1, 2, 3]` å’Œ `[3, 2, 1]` çš„è™•ç†æ–¹å¼ä¸åŒã€‚ä½†å°æ–¼è¨±å¤šä»»å‹™ï¼Œæˆ‘å€‘éœ€è¦**æ’åˆ—ä¸è®Šæ€§** - æ¨¡å‹æ‡‰è©²å°‡å…©å€‹è¼¸å…¥è¦–ç‚ºç›¸åŒï¼Œå› ç‚ºå®ƒå€‘ä»£è¡¨åŒä¸€å€‹é›†åˆ `{1, 2, 3}`ã€‚\n",
    "\n",
    "### æ ¸å¿ƒå‰µæ–°ï¼šè®€å–-è™•ç†-å¯«å…¥\n",
    "\n",
    "```\n",
    "è®€å–ï¼ˆREADï¼‰:    ç·¨ç¢¼ç„¡åºé›†åˆï¼ˆæ’åˆ—ä¸è®Šï¼‰\n",
    "         â†“\n",
    "è™•ç†ï¼ˆPROCESSï¼‰: å°é›†åˆå…ƒç´ é€²è¡Œæ³¨æ„åŠ›æ©Ÿåˆ¶\n",
    "         â†“\n",
    "å¯«å…¥ï¼ˆWRITEï¼‰:   ç”Ÿæˆæœ‰åºè¼¸å‡ºåºåˆ—\n",
    "```\n",
    "\n",
    "### è§£æ±ºçš„æ ¸å¿ƒæŒ‘æˆ°\n",
    "\n",
    "1. **æ’åˆ—ä¸è®Šæ€§**ï¼šç·¨ç¢¼å™¨å¿…é ˆç”¢ç”Ÿç›¸åŒçš„è¡¨ç¤ºï¼Œç„¡è«–è¼¸å…¥é †åºå¦‚ä½•\n",
    "2. **å¯è®Šé›†åˆå¤§å°**ï¼šè™•ç†ä¸åŒåŸºæ•¸çš„é›†åˆ\n",
    "3. **é›†åˆä¸Šçš„æ³¨æ„åŠ›**ï¼šè§£ç¢¼å™¨å°ç„¡åºå…ƒç´ é€²è¡Œæ³¨æ„åŠ›æ©Ÿåˆ¶\n",
    "\n",
    "### æ‡‰ç”¨å ´æ™¯\n",
    "- æ•¸å­—æ’åº\n",
    "- æ‰¾å‡º k å€‹æœ€å¤§/æœ€å°å…ƒç´ \n",
    "- é›†åˆé‹ç®—ï¼ˆè¯é›†ã€äº¤é›†ï¼‰\n",
    "- åœ–å•é¡Œï¼ˆç¯€é»é †åºç„¡é—œç·Šè¦ï¼‰\n",
    "- é»é›²è™•ç†\n",
    "\n",
    "### æ¶æ§‹æ¯”è¼ƒ\n",
    "\n",
    "| æ–¹æ³• | æ’åˆ—ä¸è®Šï¼Ÿ | ä½¿ç”¨å ´æ™¯ |\n",
    "|----------|----------------------|----------|\n",
    "| **LSTM ç·¨ç¢¼å™¨** | âŒ å¦ | é †åºé‡è¦çš„åºåˆ— |\n",
    "| **ç¸½å’Œ/å¹³å‡æ± åŒ–** | âœ… æ˜¯ | é›†åˆï¼ˆé †åºä¸é‡è¦ï¼‰ |\n",
    "| **æ³¨æ„åŠ›æ± åŒ–** | âœ… æ˜¯ | åŸºæ–¼å…§å®¹é‡è¦æ€§çš„é›†åˆ |\n",
    "| **DeepSets** | âœ… æ˜¯ | ä¸€èˆ¬é›†åˆå‡½æ•¸ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸€ç¯€ï¼šæ’åˆ—ä¸è®Šçš„é›†åˆç·¨ç¢¼å™¨\n",
    "\n",
    "é—œéµæ´è¦‹ï¼šå‡½æ•¸ `f` æ˜¯**æ’åˆ—ä¸è®Š**çš„ï¼Œå¦‚æœï¼š\n",
    "\n",
    "```\n",
    "f({xâ‚, xâ‚‚, ..., xâ‚™}) = f({xÏ€(1), xÏ€(2), ..., xÏ€(n)})\n",
    "```\n",
    "\n",
    "å°æ–¼ä»»æ„æ’åˆ— Ï€ã€‚\n",
    "\n",
    "### å¯¦ä½œç­–ç•¥ï¼š\n",
    "\n",
    "1. **ç¸½å’Œæ± åŒ–**ï¼š`f(X) = Î£áµ¢ Ï†(xáµ¢)`\n",
    "2. **å¹³å‡æ± åŒ–**ï¼š`f(X) = (1/n) Î£áµ¢ Ï†(xáµ¢)`\n",
    "3. **æœ€å¤§æ± åŒ–**ï¼š`f(X) = maxáµ¢ Ï†(xáµ¢)`ï¼ˆé€å…ƒç´ ï¼‰\n",
    "4. **æ³¨æ„åŠ›æ± åŒ–**ï¼šä½¿ç”¨å­¸ç¿’çš„æ³¨æ„åŠ›é€²è¡ŒåŠ æ¬Šæ±‚å’Œ\n",
    "\n",
    "æ‰€æœ‰é€™äº›éƒ½æ˜¯æ’åˆ—ä¸è®Šçš„ï¼Œå› ç‚ºé€™äº›é‹ç®—èˆ‡æ’åˆ—å¯äº¤æ›ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ç¬¬ä¸€ç¯€ï¼šæ’åˆ—ä¸è®Šçš„é›†åˆç·¨ç¢¼å™¨\n",
    "# ================================================================\n",
    "\n",
    "class SetEncoder:\n",
    "    \"\"\"\n",
    "    ç„¡åºé›†åˆçš„æ’åˆ—ä¸è®Šç·¨ç¢¼å™¨ã€‚\n",
    "    \n",
    "    ç­–ç•¥ï¼šåµŒå…¥æ¯å€‹å…ƒç´ ï¼Œç„¶å¾Œåœ¨é›†åˆç¶­åº¦ä¸Šé€²è¡Œæ± åŒ–ã€‚\n",
    "    æ± åŒ–é¸é …ï¼šmeanï¼ˆå¹³å‡ï¼‰ã€sumï¼ˆç¸½å’Œï¼‰ã€maxï¼ˆæœ€å¤§ï¼‰ã€attentionï¼ˆæ³¨æ„åŠ›ï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, pooling='mean'):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.pooling = pooling\n",
    "        \n",
    "        # é€å…ƒç´ åµŒå…¥ï¼ˆæ‡‰ç”¨æ–¼æ¯å€‹é›†åˆå…ƒç´ ï¼‰\n",
    "        self.W_embed = np.random.randn(input_dim, hidden_dim) * 0.1\n",
    "        self.b_embed = np.zeros(hidden_dim)\n",
    "        \n",
    "        # ç”¨æ–¼æ³¨æ„åŠ›æ± åŒ–\n",
    "        if pooling == 'attention':\n",
    "            self.W_attn = np.random.randn(hidden_dim, 1) * 0.1\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        ç·¨ç¢¼å…ƒç´ é›†åˆã€‚\n",
    "        \n",
    "        åƒæ•¸ï¼š\n",
    "            X: (set_size, input_dim) - ç„¡åºé›†åˆå…ƒç´ \n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            encoding: (hidden_dim,) - ä»£è¡¨é›†åˆçš„å–®ä¸€å‘é‡\n",
    "            element_encodings: (set_size, hidden_dim) - å„å…ƒç´ åµŒå…¥\n",
    "        \"\"\"\n",
    "        # ç¨ç«‹åµŒå…¥æ¯å€‹å…ƒç´ \n",
    "        # å°é›†åˆä¸­æ¯å€‹ x è¨ˆç®— Ï†(x)\n",
    "        element_encodings = np.tanh(X @ self.W_embed + self.b_embed)  # (set_size, hidden_dim)\n",
    "        \n",
    "        # åœ¨é›†åˆç¶­åº¦ä¸Šé€²è¡Œæ± åŒ–ï¼ˆæ’åˆ—ä¸è®Šé‹ç®—ï¼‰\n",
    "        if self.pooling == 'mean':\n",
    "            encoding = np.mean(element_encodings, axis=0)\n",
    "        elif self.pooling == 'sum':\n",
    "            encoding = np.sum(element_encodings, axis=0)\n",
    "        elif self.pooling == 'max':\n",
    "            encoding = np.max(element_encodings, axis=0)\n",
    "        elif self.pooling == 'attention':\n",
    "            # å°é›†åˆå…ƒç´ çš„å¯å­¸ç¿’æ³¨æ„åŠ›æ¬Šé‡\n",
    "            attn_logits = element_encodings @ self.W_attn  # (set_size, 1)\n",
    "            attn_weights = softmax(attn_logits.flatten())\n",
    "            encoding = attn_weights @ element_encodings  # åŠ æ¬Šæ±‚å’Œ\n",
    "        \n",
    "        return encoding, element_encodings\n",
    "\n",
    "\n",
    "# æ¸¬è©¦æ’åˆ—ä¸è®Šæ€§\n",
    "print(\"æ¸¬è©¦æ’åˆ—ä¸è®Šæ€§\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "encoder = SetEncoder(input_dim=1, hidden_dim=16, pooling='mean')\n",
    "\n",
    "# å»ºç«‹ä¸€å€‹é›†åˆåŠå…¶æ’åˆ—\n",
    "set1 = np.array([[1.0], [2.0], [3.0], [4.0]])\n",
    "set2 = np.array([[4.0], [2.0], [1.0], [3.0]])  # ç›¸åŒå…ƒç´ ï¼Œä¸åŒé †åº\n",
    "\n",
    "enc1, _ = encoder.forward(set1)\n",
    "enc2, _ = encoder.forward(set2)\n",
    "\n",
    "print(f\"é›†åˆ 1ï¼š{set1.flatten()}\")\n",
    "print(f\"é›†åˆ 2ï¼š{set2.flatten()}\")\n",
    "print(f\"\\nç·¨ç¢¼å·®ç•°ï¼š{np.linalg.norm(enc1 - enc2):.10f}\")\n",
    "print(f\"ç·¨ç¢¼æ˜¯å¦ç›¸åŒï¼Ÿ{np.allclose(enc1, enc2)}\")\n",
    "print(\"\\nâœ“ æ’åˆ—ä¸è®Šæ€§é©—è­‰é€šéï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬äºŒç¯€ï¼šLSTM ç·¨ç¢¼å™¨ï¼ˆé †åºæ•æ„ŸåŸºç·šï¼‰\n",
    "\n",
    "ä½œç‚ºæ¯”è¼ƒï¼Œæˆ‘å€‘å¯¦ä½œä¸€å€‹æ¨™æº–çš„ LSTM ç·¨ç¢¼å™¨ï¼Œå®ƒ**å°**è¼¸å…¥é †åºæ•æ„Ÿã€‚\n",
    "\n",
    "é€™åœ¨æ’åˆ—è¼¸å…¥ä¸Šæœƒå¤±æ•—ï¼Œå±•ç¤ºäº†ç‚ºä»€éº¼é›†åˆä»»å‹™éœ€è¦æ’åˆ—ä¸è®Šæ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ç¬¬äºŒç¯€ï¼šLSTM ç·¨ç¢¼å™¨ï¼ˆé †åºæ•æ„ŸåŸºç·šï¼‰\n",
    "# ================================================================\n",
    "\n",
    "class LSTMEncoder:\n",
    "    \"\"\"\n",
    "    æ¨™æº– LSTM ç·¨ç¢¼å™¨ - é †åºæ•æ„Ÿã€‚\n",
    "    \n",
    "    é€™å°‡ä½œç‚ºåŸºç·šï¼Œå±•ç¤ºåœ¨é›†åˆä»»å‹™ä¸Šä½¿ç”¨é †åºæ•æ„Ÿæ¨¡å‹æœƒç™¼ç”Ÿä»€éº¼ã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # LSTM åƒæ•¸ï¼ˆè¼¸å…¥é–€ã€éºå¿˜é–€ã€è¼¸å‡ºé–€ã€å€™é¸é–€ï¼‰\n",
    "        self.W_lstm = np.random.randn(input_dim + hidden_dim, 4 * hidden_dim) * 0.1\n",
    "        self.b_lstm = np.zeros(4 * hidden_dim)\n",
    "        \n",
    "        # åˆå§‹ç‹€æ…‹\n",
    "        self.h = None\n",
    "        self.c = None\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.h = np.zeros(self.hidden_dim)\n",
    "        self.c = np.zeros(self.hidden_dim)\n",
    "    \n",
    "    def step(self, x):\n",
    "        \"\"\"å–®ä¸€ LSTM æ­¥é©Ÿã€‚\"\"\"\n",
    "        if self.h is None:\n",
    "            self.reset_state()\n",
    "        \n",
    "        # ä¸²æ¥è¼¸å…¥å’Œéš±è—ç‹€æ…‹\n",
    "        concat = np.concatenate([x, self.h])\n",
    "        \n",
    "        # è¨ˆç®—å„é–˜é–€\n",
    "        gates = concat @ self.W_lstm + self.b_lstm\n",
    "        i, f, o, g = np.split(gates, 4)\n",
    "        \n",
    "        # æ‡‰ç”¨æ¿€æ´»å‡½æ•¸\n",
    "        i = 1 / (1 + np.exp(-i))  # è¼¸å…¥é–€\n",
    "        f = 1 / (1 + np.exp(-f))  # éºå¿˜é–€\n",
    "        o = 1 / (1 + np.exp(-o))  # è¼¸å‡ºé–€\n",
    "        g = np.tanh(g)            # å€™é¸å€¼\n",
    "        \n",
    "        # æ›´æ–°ç´°èƒç‹€æ…‹å’Œéš±è—ç‹€æ…‹\n",
    "        self.c = f * self.c + i * g\n",
    "        self.h = o * np.tanh(self.c)\n",
    "        \n",
    "        return self.h\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        ç·¨ç¢¼åºåˆ—ã€‚\n",
    "        \n",
    "        åƒæ•¸ï¼š\n",
    "            X: (seq_len, input_dim) - è¼¸å…¥åºåˆ—\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            encoding: (hidden_dim,) - æœ€çµ‚éš±è—ç‹€æ…‹\n",
    "            all_hidden: (seq_len, hidden_dim) - æ‰€æœ‰éš±è—ç‹€æ…‹\n",
    "        \"\"\"\n",
    "        self.reset_state()\n",
    "        \n",
    "        all_hidden = []\n",
    "        for t in range(len(X)):\n",
    "            h = self.step(X[t])\n",
    "            all_hidden.append(h)\n",
    "        \n",
    "        return self.h, np.array(all_hidden)\n",
    "\n",
    "\n",
    "# æ¸¬è©¦é †åºæ•æ„Ÿæ€§\n",
    "print(\"æ¸¬è©¦é †åºæ•æ„Ÿæ€§ï¼ˆLSTM ç·¨ç¢¼å™¨ï¼‰\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "lstm_encoder = LSTMEncoder(input_dim=1, hidden_dim=16)\n",
    "\n",
    "enc1, _ = lstm_encoder.forward(set1)\n",
    "enc2, _ = lstm_encoder.forward(set2)\n",
    "\n",
    "print(f\"åºåˆ— 1ï¼š{set1.flatten()}\")\n",
    "print(f\"åºåˆ— 2ï¼š{set2.flatten()}\")\n",
    "print(f\"\\nç·¨ç¢¼å·®ç•°ï¼š{np.linalg.norm(enc1 - enc2):.6f}\")\n",
    "print(f\"ç·¨ç¢¼æ˜¯å¦ç›¸åŒï¼Ÿ{np.allclose(enc1, enc2)}\")\n",
    "print(\"\\nâœ“ LSTM æ˜¯é †åºæ•æ„Ÿçš„ï¼ˆç¬¦åˆé æœŸï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸‰ç¯€ï¼šæ³¨æ„åŠ›æ©Ÿåˆ¶\n",
    "\n",
    "è§£ç¢¼å™¨ä½¿ç”¨**åŸºæ–¼å…§å®¹çš„æ³¨æ„åŠ›**ä¾†é—œæ³¨ç›¸é—œçš„é›†åˆå…ƒç´ ã€‚\n",
    "\n",
    "### æ³¨æ„åŠ›å…¬å¼ï¼š\n",
    "\n",
    "```\n",
    "score(hâ‚œ, eáµ¢) = váµ€ tanh(Wâ‚hâ‚œ + Wâ‚‚eáµ¢)\n",
    "Î±â‚œ = softmax(scores)\n",
    "context = Î£áµ¢ Î±â‚œ,áµ¢ Â· eáµ¢\n",
    "```\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- `hâ‚œ` = æ™‚é–“ t çš„è§£ç¢¼å™¨éš±è—ç‹€æ…‹\n",
    "- `eáµ¢` = é›†åˆç·¨ç¢¼å™¨çš„ç¬¬ i å€‹å…ƒç´ ç·¨ç¢¼\n",
    "- `context` = å…ƒç´ ç·¨ç¢¼çš„åŠ æ¬Šå’Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ç¬¬ä¸‰ç¯€ï¼šæ³¨æ„åŠ›æ©Ÿåˆ¶\n",
    "# ================================================================\n",
    "\n",
    "class Attention:\n",
    "    \"\"\"\n",
    "    åŸºæ–¼å…§å®¹çš„æ³¨æ„åŠ›æ©Ÿåˆ¶ã€‚\n",
    "    \n",
    "    å…è¨±è§£ç¢¼å™¨é—œæ³¨è¼¸å…¥é›†åˆä¸­çš„ç›¸é—œå…ƒç´ ã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # æ³¨æ„åŠ›åƒæ•¸\n",
    "        self.W_query = np.random.randn(hidden_dim, hidden_dim) * 0.1\n",
    "        self.W_key = np.random.randn(hidden_dim, hidden_dim) * 0.1\n",
    "        self.v = np.random.randn(hidden_dim) * 0.1\n",
    "    \n",
    "    def forward(self, query, keys):\n",
    "        \"\"\"\n",
    "        è¨ˆç®—æ³¨æ„åŠ›æ¬Šé‡å’Œä¸Šä¸‹æ–‡å‘é‡ã€‚\n",
    "        \n",
    "        åƒæ•¸ï¼š\n",
    "            query: (hidden_dim,) - è§£ç¢¼å™¨éš±è—ç‹€æ…‹\n",
    "            keys: (set_size, hidden_dim) - ç·¨ç¢¼å™¨å…ƒç´ åµŒå…¥\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            context: (hidden_dim,) - keys çš„åŠ æ¬Šå’Œ\n",
    "            weights: (set_size,) - æ³¨æ„åŠ›æ¬Šé‡\n",
    "        \"\"\"\n",
    "        # è½‰æ› query å’Œ keys\n",
    "        q = query @ self.W_query  # (hidden_dim,)\n",
    "        k = keys @ self.W_key     # (set_size, hidden_dim)\n",
    "        \n",
    "        # è¨ˆç®—æ³¨æ„åŠ›åˆ†æ•¸\n",
    "        # score(q, k_i) = v^T tanh(q + k_i)\n",
    "        scores = np.tanh(q + k) @ self.v  # (set_size,)\n",
    "        \n",
    "        # Softmax å¾—åˆ°æ³¨æ„åŠ›æ¬Šé‡\n",
    "        weights = softmax(scores)\n",
    "        \n",
    "        # è¨ˆç®—ä¸Šä¸‹æ–‡ä½œç‚ºåŠ æ¬Šå’Œ\n",
    "        context = weights @ keys  # (hidden_dim,)\n",
    "        \n",
    "        return context, weights\n",
    "\n",
    "\n",
    "# æ¸¬è©¦æ³¨æ„åŠ›æ©Ÿåˆ¶\n",
    "print(\"æ¸¬è©¦æ³¨æ„åŠ›æ©Ÿåˆ¶\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "attention = Attention(hidden_dim=16)\n",
    "\n",
    "# æ¨¡æ“¬è§£ç¢¼å™¨ç‹€æ…‹å’Œç·¨ç¢¼å™¨è¼¸å‡º\n",
    "query = np.random.randn(16)\n",
    "keys = np.random.randn(5, 16)  # 5 å€‹é›†åˆå…ƒç´ \n",
    "\n",
    "context, weights = attention.forward(query, keys)\n",
    "\n",
    "print(f\"Query å½¢ç‹€ï¼š{query.shape}\")\n",
    "print(f\"Keys å½¢ç‹€ï¼š{keys.shape}\")\n",
    "print(f\"Context å½¢ç‹€ï¼š{context.shape}\")\n",
    "print(f\"\\næ³¨æ„åŠ›æ¬Šé‡ï¼š{weights}\")\n",
    "print(f\"æ¬Šé‡ç¸½å’Œï¼š{weights.sum():.6f}ï¼ˆæ‡‰ç‚º 1.0ï¼‰\")\n",
    "print(\"\\nâœ“ æ³¨æ„åŠ›æ©Ÿåˆ¶é‹ä½œæ­£ç¢º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬å››ç¯€ï¼šå¸¶æ³¨æ„åŠ›çš„ LSTM è§£ç¢¼å™¨\n",
    "\n",
    "è§£ç¢¼å™¨é€ä¸€ç”Ÿæˆè¼¸å‡ºå…ƒç´ ï¼Œåœ¨æ¯ä¸€æ­¥å°è¼¸å…¥é›†åˆé€²è¡Œæ³¨æ„åŠ›ã€‚\n",
    "\n",
    "### è§£ç¢¼éç¨‹ï¼š\n",
    "\n",
    "```\n",
    "åœ¨æ¯å€‹æ™‚é–“æ­¥ tï¼š\n",
    "1. ä½¿ç”¨ç•¶å‰éš±è—ç‹€æ…‹ hâ‚œ è¨ˆç®—å°è¼¸å…¥é›†åˆçš„æ³¨æ„åŠ›\n",
    "2. å¾æ³¨æ„åŠ›ç²å–ä¸Šä¸‹æ–‡å‘é‡\n",
    "3. å°‡ä¸Šä¸‹æ–‡èˆ‡å‰ä¸€å€‹è¼¸å‡ºçµåˆ\n",
    "4. æ›´æ–° LSTM ç‹€æ…‹\n",
    "5. é æ¸¬ä¸‹ä¸€å€‹è¼¸å‡ºå…ƒç´ \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ç¬¬å››ç¯€ï¼šå¸¶æ³¨æ„åŠ›çš„ LSTM è§£ç¢¼å™¨\n",
    "# ================================================================\n",
    "\n",
    "class LSTMDecoder:\n",
    "    \"\"\"\n",
    "    å¸¶æœ‰å°è¼¸å…¥é›†åˆæ³¨æ„åŠ›çš„ LSTM è§£ç¢¼å™¨ã€‚\n",
    "    \n",
    "    é€éå°é›†åˆå…ƒç´ é€²è¡Œæ³¨æ„åŠ›ä¾†ç”Ÿæˆè¼¸å‡ºåºåˆ—ã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_dim, hidden_dim):\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # LSTM åƒæ•¸\n",
    "        # è¼¸å…¥ï¼š[prev_output, context]\n",
    "        input_size = output_dim + hidden_dim\n",
    "        self.W_lstm = np.random.randn(input_size + hidden_dim, 4 * hidden_dim) * 0.1\n",
    "        self.b_lstm = np.zeros(4 * hidden_dim)\n",
    "        \n",
    "        # è¼¸å‡ºæŠ•å½±\n",
    "        self.W_out = np.random.randn(hidden_dim, output_dim) * 0.1\n",
    "        self.b_out = np.zeros(output_dim)\n",
    "        \n",
    "        # æ³¨æ„åŠ›\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        \n",
    "        # ç‹€æ…‹\n",
    "        self.h = None\n",
    "        self.c = None\n",
    "    \n",
    "    def init_state(self, initial_state):\n",
    "        \"\"\"å¾ç·¨ç¢¼å™¨åˆå§‹åŒ–è§£ç¢¼å™¨ç‹€æ…‹ã€‚\"\"\"\n",
    "        self.h = initial_state.copy()\n",
    "        self.c = np.zeros(self.hidden_dim)\n",
    "    \n",
    "    def step(self, prev_output, encoder_outputs):\n",
    "        \"\"\"\n",
    "        å–®ä¸€è§£ç¢¼å™¨æ­¥é©Ÿã€‚\n",
    "        \n",
    "        åƒæ•¸ï¼š\n",
    "            prev_output: (output_dim,) - å‰ä¸€å€‹è¼¸å‡ºï¼ˆæˆ–é–‹å§‹æ¨™è¨˜ï¼‰\n",
    "            encoder_outputs: (set_size, hidden_dim) - é›†åˆå…ƒç´ åµŒå…¥\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            output: (output_dim,) - é æ¸¬è¼¸å‡º\n",
    "            attn_weights: (set_size,) - æ³¨æ„åŠ›æ¬Šé‡\n",
    "        \"\"\"\n",
    "        # 1. è¨ˆç®—å°ç·¨ç¢¼å™¨è¼¸å‡ºçš„æ³¨æ„åŠ›\n",
    "        context, attn_weights = self.attention.forward(self.h, encoder_outputs)\n",
    "        \n",
    "        # 2. çµåˆå‰ä¸€å€‹è¼¸å‡ºå’Œä¸Šä¸‹æ–‡\n",
    "        lstm_input = np.concatenate([prev_output, context])\n",
    "        \n",
    "        # 3. LSTM æ­¥é©Ÿ\n",
    "        concat = np.concatenate([lstm_input, self.h])\n",
    "        gates = concat @ self.W_lstm + self.b_lstm\n",
    "        i, f, o, g = np.split(gates, 4)\n",
    "        \n",
    "        i = 1 / (1 + np.exp(-i))\n",
    "        f = 1 / (1 + np.exp(-f))\n",
    "        o = 1 / (1 + np.exp(-o))\n",
    "        g = np.tanh(g)\n",
    "        \n",
    "        self.c = f * self.c + i * g\n",
    "        self.h = o * np.tanh(self.c)\n",
    "        \n",
    "        # 4. é æ¸¬è¼¸å‡º\n",
    "        output = self.h @ self.W_out + self.b_out\n",
    "        \n",
    "        return output, attn_weights\n",
    "    \n",
    "    def forward(self, encoder_outputs, target_length, start_token=None):\n",
    "        \"\"\"\n",
    "        ç”Ÿæˆå®Œæ•´è¼¸å‡ºåºåˆ—ã€‚\n",
    "        \n",
    "        åƒæ•¸ï¼š\n",
    "            encoder_outputs: (set_size, hidden_dim) - ç·¨ç¢¼çš„é›†åˆå…ƒç´ \n",
    "            target_length: int - è¼¸å‡ºåºåˆ—é•·åº¦\n",
    "            start_token: (output_dim,) - åˆå§‹è¼¸å…¥ï¼ˆé è¨­ï¼šé›¶ï¼‰\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            outputs: (target_length, output_dim) - é æ¸¬è¼¸å‡º\n",
    "            all_attn_weights: (target_length, set_size) - æ¯æ­¥çš„æ³¨æ„åŠ›\n",
    "        \"\"\"\n",
    "        if start_token is None:\n",
    "            start_token = np.zeros(self.output_dim)\n",
    "        \n",
    "        # ç”¨ç·¨ç¢¼å™¨è¼¸å‡ºçš„å¹³å‡å€¼åˆå§‹åŒ–è§£ç¢¼å™¨ç‹€æ…‹\n",
    "        initial_state = np.mean(encoder_outputs, axis=0)\n",
    "        self.init_state(initial_state)\n",
    "        \n",
    "        outputs = []\n",
    "        all_attn_weights = []\n",
    "        \n",
    "        prev_output = start_token\n",
    "        \n",
    "        for t in range(target_length):\n",
    "            output, attn_weights = self.step(prev_output, encoder_outputs)\n",
    "            outputs.append(output)\n",
    "            all_attn_weights.append(attn_weights)\n",
    "            prev_output = output  # ä½¿ç”¨é æ¸¬è¼¸å‡ºä½œç‚ºä¸‹ä¸€å€‹è¼¸å…¥\n",
    "        \n",
    "        return np.array(outputs), np.array(all_attn_weights)\n",
    "\n",
    "\n",
    "print(\"âœ“ å¸¶æ³¨æ„åŠ›çš„ LSTM è§£ç¢¼å™¨å·²å¯¦ä½œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬äº”ç¯€ï¼šå®Œæ•´çš„é›†åˆ Seq2Seq æ¨¡å‹\n",
    "\n",
    "æ•´åˆæ‰€æœ‰å…ƒä»¶ï¼š**è®€å–-è™•ç†-å¯«å…¥**æ¶æ§‹ã€‚\n",
    "\n",
    "### æ¨¡å‹è®Šé«”ï¼š\n",
    "\n",
    "1. **Set2Seqï¼ˆæˆ‘å€‘çš„ï¼‰**ï¼šæ’åˆ—ä¸è®Šç·¨ç¢¼å™¨ + æ³¨æ„åŠ›è§£ç¢¼å™¨\n",
    "2. **Seq2Seqï¼ˆåŸºç·šï¼‰**ï¼šLSTM ç·¨ç¢¼å™¨ + æ³¨æ„åŠ›è§£ç¢¼å™¨ï¼ˆé †åºæ•æ„Ÿï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ç¬¬äº”ç¯€ï¼šå®Œæ•´çš„é›†åˆ Seq2Seq æ¨¡å‹\n",
    "# ================================================================\n",
    "\n",
    "class Set2Seq:\n",
    "    \"\"\"\n",
    "    å®Œæ•´çš„é›†åˆåºåˆ—åˆ°åºåˆ—æ¨¡å‹ã€‚\n",
    "    \n",
    "    å…ƒä»¶ï¼š\n",
    "    - æ’åˆ—ä¸è®Šé›†åˆç·¨ç¢¼å™¨\n",
    "    - æ³¨æ„åŠ›æ©Ÿåˆ¶\n",
    "    - LSTM è§£ç¢¼å™¨\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, pooling='mean'):\n",
    "        self.encoder = SetEncoder(input_dim, hidden_dim, pooling=pooling)\n",
    "        self.decoder = LSTMDecoder(output_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, input_set, target_length):\n",
    "        \"\"\"\n",
    "        å‰å‘å‚³éï¼šé›†åˆ â†’ åºåˆ—\n",
    "        \n",
    "        åƒæ•¸ï¼š\n",
    "            input_set: (set_size, input_dim) - ç„¡åºè¼¸å…¥é›†åˆ\n",
    "            target_length: int - è¼¸å‡ºåºåˆ—é•·åº¦\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            outputs: (target_length, output_dim) - é æ¸¬åºåˆ—\n",
    "            attn_weights: (target_length, set_size) - æ³¨æ„åŠ›æ¬Šé‡\n",
    "        \"\"\"\n",
    "        # ç·¨ç¢¼é›†åˆï¼ˆæ’åˆ—ä¸è®Šï¼‰\n",
    "        _, element_encodings = self.encoder.forward(input_set)\n",
    "        \n",
    "        # è§£ç¢¼ç‚ºåºåˆ—ï¼ˆå¸¶æ³¨æ„åŠ›ï¼‰\n",
    "        outputs, attn_weights = self.decoder.forward(\n",
    "            element_encodings, \n",
    "            target_length\n",
    "        )\n",
    "        \n",
    "        return outputs, attn_weights\n",
    "\n",
    "\n",
    "class Seq2Seq:\n",
    "    \"\"\"\n",
    "    åŸºç·šï¼šé †åºæ•æ„Ÿçš„åºåˆ—åˆ°åºåˆ—æ¨¡å‹ã€‚\n",
    "    \n",
    "    ä½¿ç”¨ LSTM ç·¨ç¢¼å™¨è€Œéé›†åˆç·¨ç¢¼å™¨ã€‚\n",
    "    åœ¨æ’åˆ—è¼¸å…¥ä¸Šæœƒå¤±æ•—ã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        self.encoder = LSTMEncoder(input_dim, hidden_dim)\n",
    "        self.decoder = LSTMDecoder(output_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, input_seq, target_length):\n",
    "        # ç·¨ç¢¼åºåˆ—ï¼ˆé †åºæ•æ„Ÿï¼‰\n",
    "        _, all_hidden = self.encoder.forward(input_seq)\n",
    "        \n",
    "        # è§£ç¢¼\n",
    "        outputs, attn_weights = self.decoder.forward(\n",
    "            all_hidden,\n",
    "            target_length\n",
    "        )\n",
    "        \n",
    "        return outputs, attn_weights\n",
    "\n",
    "\n",
    "print(\"âœ“ å®Œæ•´çš„ Set2Seq å’Œ Seq2Seq æ¨¡å‹å·²å¯¦ä½œ\")\n",
    "print(\"\\næ¨¡å‹æ¯”è¼ƒï¼š\")\n",
    "print(\"  Set2Seqï¼šæ’åˆ—ä¸è®Šç·¨ç¢¼å™¨ âœ“\")\n",
    "print(\"  Seq2Seqï¼šé †åºæ•æ„Ÿ LSTM ç·¨ç¢¼å™¨ âœ—\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬å…­ç¯€ï¼šä»»å‹™ - æ•¸å­—æ’åº\n",
    "\n",
    "å±•ç¤ºé›†åˆè™•ç†çš„ç¶“å…¸ä»»å‹™ï¼š**å°ä¸€çµ„æ•¸å­—é€²è¡Œæ’åº**ã€‚\n",
    "\n",
    "### ä»»å‹™å®šç¾©ï¼š\n",
    "\n",
    "```\n",
    "è¼¸å…¥ï¼šç„¡åºé›†åˆ {3, 1, 4, 2}\n",
    "è¼¸å‡ºï¼šæ’åºå¾Œçš„åºåˆ— [1, 2, 3, 4]\n",
    "```\n",
    "\n",
    "### ç‚ºä»€éº¼é€™èƒ½æ¸¬è©¦æ’åˆ—ä¸è®Šæ€§ï¼š\n",
    "\n",
    "è¼¸å…¥ `{3,1,4,2}`ã€`{2,4,1,3}`ã€`{4,3,2,1}` éƒ½æ‡‰è©²ç”¢ç”Ÿ `[1,2,3,4]`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ç¬¬å…­ç¯€ï¼šæ’åºä»»å‹™\n",
    "# ================================================================\n",
    "\n",
    "def generate_sorting_data(num_samples=1000, set_size=5, value_range=10):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆæ’åºä»»å‹™çš„è³‡æ–™é›†ã€‚\n",
    "    \n",
    "    åƒæ•¸ï¼š\n",
    "        num_samplesï¼šè¨“ç·´æ¨£æœ¬æ•¸\n",
    "        set_sizeï¼šæ¯å€‹é›†åˆçš„å…ƒç´ æ•¸é‡\n",
    "        value_rangeï¼šå€¼ç¯„åœåœ¨ [0, value_range)\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "        X: (num_samples, set_size, 1) - è¼¸å…¥é›†åˆï¼ˆç„¡åºï¼‰\n",
    "        Y: (num_samples, set_size, 1) - æ’åºå¾Œçš„åºåˆ—\n",
    "    \"\"\"\n",
    "    X = np.random.randint(0, value_range, size=(num_samples, set_size, 1)).astype(np.float32)\n",
    "    Y = np.sort(X, axis=1)  # æ²¿é›†åˆç¶­åº¦æ’åº\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def normalize_data(X, Y, value_range):\n",
    "    \"\"\"æ¨™æº–åŒ–åˆ° [0, 1] ç¯„åœã€‚\"\"\"\n",
    "    return X / value_range, Y / value_range\n",
    "\n",
    "\n",
    "# ç”Ÿæˆæ¨£æœ¬è³‡æ–™\n",
    "X_train, Y_train = generate_sorting_data(num_samples=100, set_size=5, value_range=10)\n",
    "X_train, Y_train = normalize_data(X_train, Y_train, value_range=10)\n",
    "\n",
    "print(\"æ’åºä»»å‹™è³‡æ–™é›†\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"è¨“ç·´æ¨£æœ¬æ•¸ï¼š{len(X_train)}\")\n",
    "print(f\"é›†åˆå¤§å°ï¼š{X_train.shape[1]}\")\n",
    "print(f\"å€¼ç¶­åº¦ï¼š{X_train.shape[2]}\")\n",
    "print(\"\\nç¯„ä¾‹ï¼š\")\n",
    "print(f\"  è¼¸å…¥é›†åˆï¼š     {(X_train[0].flatten() * 10).astype(int)}\")\n",
    "print(f\"  æ’åºå¾Œè¼¸å‡ºï¼š   {(Y_train[0].flatten() * 10).astype(int)}\")\n",
    "print(\"\\nâœ“ æ’åºä»»å‹™è³‡æ–™å·²ç”Ÿæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸ƒç¯€ï¼šè¨“ç·´è¿´åœˆ\n",
    "\n",
    "è¨“ç·´å…©å€‹æ¨¡å‹ï¼ˆSet2Seq å’Œ Seq2Seqï¼‰ä»¥æ¯”è¼ƒæ•ˆèƒ½ã€‚\n",
    "\n",
    "### è¨“ç·´æµç¨‹ï¼š\n",
    "1. é€šéç·¨ç¢¼å™¨å’Œè§£ç¢¼å™¨çš„å‰å‘å‚³é\n",
    "2. è¨ˆç®—é æ¸¬å’Œç›®æ¨™ä¹‹é–“çš„ MSE æå¤±\n",
    "3. ï¼ˆå®Œæ•´å¯¦ä½œä¸­ï¼šåå‘å‚³æ’­å’Œæ¬Šé‡æ›´æ–°ï¼‰\n",
    "\n",
    "**æ³¨æ„**ï¼šé€™æ˜¯å‰å‘å‚³éçš„å±•ç¤ºã€‚å°æ–¼å¯¦éš›è¨“ç·´ï¼Œæ‚¨éœ€è¦æ¢¯åº¦è¨ˆç®—ï¼ˆé¡ä¼¼æ–¼è«–æ–‡ 18 çš„ç¬¬ 11 ç¯€ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ç¬¬ä¸ƒç¯€ï¼šè¨“ç·´ï¼ˆå‰å‘å‚³éé©—è­‰ï¼‰\n",
    "# ================================================================\n",
    "\n",
    "def compute_loss(predictions, targets):\n",
    "    \"\"\"å‡æ–¹èª¤å·®æå¤±ã€‚\"\"\"\n",
    "    return np.mean((predictions - targets) ** 2)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, Y, num_samples=50):\n",
    "    \"\"\"\n",
    "    åœ¨è³‡æ–™é›†ä¸Šè©•ä¼°æ¨¡å‹ã€‚\n",
    "    \n",
    "    è¿”å›æ¨£æœ¬çš„å¹³å‡æå¤±ã€‚\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i in range(min(num_samples, len(X))):\n",
    "        input_data = X[i]\n",
    "        target = Y[i]\n",
    "        \n",
    "        # å‰å‘å‚³é\n",
    "        predictions, _ = model.forward(input_data, target_length=len(target))\n",
    "        \n",
    "        # è¨ˆç®—æå¤±\n",
    "        loss = compute_loss(predictions, target)\n",
    "        total_loss += loss\n",
    "    \n",
    "    return total_loss / num_samples\n",
    "\n",
    "\n",
    "print(\"è©•ä¼°æ¨¡å‹ï¼ˆåƒ…å‰å‘å‚³éï¼‰\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "set2seq = Set2Seq(input_dim=1, output_dim=1, hidden_dim=32, pooling='mean')\n",
    "seq2seq = Seq2Seq(input_dim=1, output_dim=1, hidden_dim=32)\n",
    "\n",
    "# åœ¨åŸå§‹è³‡æ–™ä¸Šè©•ä¼°\n",
    "print(\"\\n[1] åœ¨åŸå§‹é †åºä¸Šè©•ä¼°ï¼š\")\n",
    "loss_set2seq = evaluate_model(set2seq, X_train, Y_train, num_samples=20)\n",
    "loss_seq2seq = evaluate_model(seq2seq, X_train, Y_train, num_samples=20)\n",
    "\n",
    "print(f\"  Set2Seq æå¤±ï¼š{loss_set2seq:.6f}\")\n",
    "print(f\"  Seq2Seq æå¤±ï¼š{loss_seq2seq:.6f}\")\n",
    "\n",
    "# å»ºç«‹è³‡æ–™çš„æ’åˆ—ç‰ˆæœ¬\n",
    "X_permuted = X_train.copy()\n",
    "for i in range(len(X_permuted)):\n",
    "    perm = np.random.permutation(X_permuted.shape[1])\n",
    "    X_permuted[i] = X_permuted[i][perm]\n",
    "\n",
    "# åœ¨æ’åˆ—è³‡æ–™ä¸Šè©•ä¼°ï¼ˆç›®æ¨™ä¿æŒä¸è®Š - ä»ç„¶æ˜¯æ’åºå¾Œçš„ï¼ï¼‰\n",
    "print(\"\\n[2] åœ¨æ’åˆ—é †åºä¸Šè©•ä¼°ï¼š\")\n",
    "loss_set2seq_perm = evaluate_model(set2seq, X_permuted, Y_train, num_samples=20)\n",
    "loss_seq2seq_perm = evaluate_model(seq2seq, X_permuted, Y_train, num_samples=20)\n",
    "\n",
    "print(f\"  Set2Seq æå¤±ï¼š{loss_set2seq_perm:.6f}\")\n",
    "print(f\"  Seq2Seq æå¤±ï¼š{loss_seq2seq_perm:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"åˆ†æï¼š\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Set2Seq æå¤±è®ŠåŒ–ï¼š{abs(loss_set2seq - loss_set2seq_perm):.6f}ï¼ˆæ‡‰æ¥è¿‘ 0ï¼‰\")\n",
    "print(f\"Seq2Seq æå¤±è®ŠåŒ–ï¼š{abs(loss_seq2seq - loss_seq2seq_perm):.6f}ï¼ˆå¯èƒ½è¼ƒå¤§ï¼‰\")\n",
    "print(\"\\nâœ“ Set2Seq æ˜¯æ’åˆ—ä¸è®Šçš„ï¼\")\n",
    "print(\"âœ— Seq2Seq æ˜¯é †åºæ•æ„Ÿçš„ï¼ˆç¬¦åˆé æœŸï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬å…«ç¯€ï¼šè¦–è¦ºåŒ–\n",
    "\n",
    "è¦–è¦ºåŒ–ï¼š\n",
    "1. **æ³¨æ„åŠ›æ¬Šé‡**ï¼šè§£ç¢¼å™¨é—œæ³¨ä»€éº¼ï¼Ÿ\n",
    "2. **æ¨¡å‹é æ¸¬**ï¼šæ’åºæ•ˆæœå¦‚ä½•ï¼Ÿ\n",
    "3. **æ’åˆ—ä¸è®Šæ€§**ï¼šè¦–è¦ºè­‰æ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ç¬¬å…«ç¯€ï¼šè¦–è¦ºåŒ–\n",
    "# ================================================================\n",
    "\n",
    "# ç¯„ä¾‹ï¼šå–®ä¸€æ’åºå¯¦ä¾‹çš„æ³¨æ„åŠ›è¦–è¦ºåŒ–\n",
    "example_idx = 0\n",
    "input_set = X_train[example_idx]\n",
    "target = Y_train[example_idx]\n",
    "\n",
    "# ç²å–é æ¸¬å’Œæ³¨æ„åŠ›æ¬Šé‡\n",
    "predictions, attn_weights = set2seq.forward(input_set, target_length=len(target))\n",
    "\n",
    "# åæ¨™æº–åŒ–ä»¥ä¾›é¡¯ç¤º\n",
    "input_values = (input_set.flatten() * 10).astype(int)\n",
    "predicted_values = predictions.flatten() * 10\n",
    "target_values = (target.flatten() * 10).astype(int)\n",
    "\n",
    "# å»ºç«‹è¦–è¦ºåŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. è¼¸å…¥ vs è¼¸å‡º\n",
    "ax = axes[0, 0]\n",
    "ax.plot(input_values, 'o-', label='è¼¸å…¥é›†åˆï¼ˆç„¡åºï¼‰', markersize=10, linewidth=2)\n",
    "ax.plot(target_values, 's-', label='ç›®æ¨™ï¼ˆå·²æ’åºï¼‰', markersize=10, linewidth=2, alpha=0.7)\n",
    "ax.plot(predicted_values, '^--', label='é æ¸¬', markersize=10, linewidth=2, alpha=0.7)\n",
    "ax.set_xlabel('ä½ç½®', fontsize=12)\n",
    "ax.set_ylabel('å€¼', fontsize=12)\n",
    "ax.set_title('æ’åºä»»å‹™ï¼šè¼¸å…¥ vs è¼¸å‡º', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. æ³¨æ„åŠ›ç†±åœ–\n",
    "ax = axes[0, 1]\n",
    "im = ax.imshow(attn_weights, aspect='auto', cmap='YlOrRd')\n",
    "ax.set_xlabel('è¼¸å…¥é›†åˆå…ƒç´ ', fontsize=12)\n",
    "ax.set_ylabel('è¼¸å‡ºæ™‚é–“æ­¥', fontsize=12)\n",
    "ax.set_title('æ³¨æ„åŠ›æ¬Šé‡\\nï¼ˆæ¯å€‹æ™‚é–“æ­¥è§£ç¢¼å™¨çš„é—œæ³¨é»ï¼‰', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax, label='æ³¨æ„åŠ›æ¬Šé‡')\n",
    "\n",
    "# æ·»åŠ è¼¸å…¥å€¼ä½œç‚º x è»¸æ¨™ç±¤\n",
    "ax.set_xticks(range(len(input_values)))\n",
    "ax.set_xticklabels(input_values)\n",
    "\n",
    "# 3. æ’åˆ—ä¸è®Šæ€§æ¸¬è©¦\n",
    "ax = axes[1, 0]\n",
    "\n",
    "# æ¸¬è©¦å¤šå€‹æ’åˆ—\n",
    "num_perms = 5\n",
    "losses_per_perm = []\n",
    "\n",
    "for _ in range(num_perms):\n",
    "    perm = np.random.permutation(len(input_set))\n",
    "    input_permuted = input_set[perm]\n",
    "    pred_perm, _ = set2seq.forward(input_permuted, target_length=len(target))\n",
    "    loss = compute_loss(pred_perm, target)\n",
    "    losses_per_perm.append(loss)\n",
    "\n",
    "ax.bar(range(num_perms), losses_per_perm, color='steelblue', alpha=0.7)\n",
    "ax.axhline(y=np.mean(losses_per_perm), color='red', linestyle='--', \n",
    "           label=f'å¹³å‡ï¼š{np.mean(losses_per_perm):.6f}')\n",
    "ax.set_xlabel('æ’åˆ—', fontsize=12)\n",
    "ax.set_ylabel('æå¤±', fontsize=12)\n",
    "ax.set_title('æ’åˆ—ä¸è®Šæ€§æ¸¬è©¦\\nï¼ˆæå¤±æ‡‰è©²ç›¸ä¼¼ï¼‰', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. æ¨¡å‹æ¯”è¼ƒ\n",
    "ax = axes[1, 1]\n",
    "\n",
    "# åœ¨ç›¸åŒç¯„ä¾‹ä¸Šæ¯”è¼ƒ Set2Seq vs Seq2Seq\n",
    "num_examples = 10\n",
    "set2seq_losses = []\n",
    "seq2seq_losses = []\n",
    "\n",
    "for i in range(num_examples):\n",
    "    input_data = X_train[i]\n",
    "    target_data = Y_train[i]\n",
    "    \n",
    "    # æ’åˆ—è¼¸å…¥\n",
    "    perm = np.random.permutation(len(input_data))\n",
    "    input_perm = input_data[perm]\n",
    "    \n",
    "    # Set2Seqï¼ˆæ‡‰è©²æœ‰æ•ˆï¼‰\n",
    "    pred_set, _ = set2seq.forward(input_perm, len(target_data))\n",
    "    loss_set = compute_loss(pred_set, target_data)\n",
    "    set2seq_losses.append(loss_set)\n",
    "    \n",
    "    # Seq2Seqï¼ˆæ‡‰è©²å¤±æ•—ï¼‰\n",
    "    pred_seq, _ = seq2seq.forward(input_perm, len(target_data))\n",
    "    loss_seq = compute_loss(pred_seq, target_data)\n",
    "    seq2seq_losses.append(loss_seq)\n",
    "\n",
    "x_pos = np.arange(num_examples)\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x_pos - width/2, set2seq_losses, width, label='Set2Seq', alpha=0.8, color='green')\n",
    "ax.bar(x_pos + width/2, seq2seq_losses, width, label='Seq2Seq', alpha=0.8, color='orange')\n",
    "\n",
    "ax.set_xlabel('ç¯„ä¾‹ï¼ˆæ’åˆ—å¾Œè¼¸å…¥ï¼‰', fontsize=12)\n",
    "ax.set_ylabel('æå¤±', fontsize=12)\n",
    "ax.set_title('æ’åˆ—è¼¸å…¥ä¸Šçš„æ¨¡å‹æ¯”è¼ƒ\\nï¼ˆè¶Šä½è¶Šå¥½ï¼‰', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('seq2seq_for_sets_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ è¦–è¦ºåŒ–å·²ç”Ÿæˆ\")\n",
    "print(f\"  å¹³å‡ Set2Seq æå¤±ï¼ˆæ’åˆ—å¾Œï¼‰ï¼š{np.mean(set2seq_losses):.6f}\")\n",
    "print(f\"  å¹³å‡ Seq2Seq æå¤±ï¼ˆæ’åˆ—å¾Œï¼‰ï¼š{np.mean(seq2seq_losses):.6f}\")\n",
    "print(f\"  Set2Seq åœ¨æ’åˆ—è¼¸å…¥ä¸Šå¥½ {np.mean(seq2seq_losses) / np.mean(set2seq_losses):.1f} å€ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¹ç¯€ï¼šæ¶ˆèç ”ç©¶\n",
    "\n",
    "æ¯”è¼ƒé›†åˆç·¨ç¢¼å™¨çš„ä¸åŒæ± åŒ–ç­–ç•¥ï¼š\n",
    "\n",
    "1. **å¹³å‡æ± åŒ–**ï¼ˆé è¨­ï¼‰\n",
    "2. **ç¸½å’Œæ± åŒ–**\n",
    "3. **æœ€å¤§æ± åŒ–**\n",
    "4. **æ³¨æ„åŠ›æ± åŒ–**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ç¬¬ä¹ç¯€ï¼šæ¶ˆèç ”ç©¶\n",
    "# ================================================================\n",
    "\n",
    "print(\"æ¶ˆèç ”ç©¶ï¼šæ± åŒ–ç­–ç•¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "pooling_methods = ['mean', 'sum', 'max', 'attention']\n",
    "results = {}\n",
    "\n",
    "for pooling in pooling_methods:\n",
    "    print(f\"\\næ¸¬è©¦ {pooling.upper()} æ± åŒ–...\")\n",
    "    \n",
    "    # ä½¿ç”¨ç‰¹å®šæ± åŒ–å»ºç«‹æ¨¡å‹\n",
    "    model = Set2Seq(input_dim=1, output_dim=1, hidden_dim=32, pooling=pooling)\n",
    "    \n",
    "    # åœ¨æ’åˆ—è³‡æ–™ä¸Šæ¸¬è©¦\n",
    "    losses = []\n",
    "    for i in range(20):\n",
    "        input_data = X_permuted[i]\n",
    "        target_data = Y_train[i]\n",
    "        \n",
    "        pred, _ = model.forward(input_data, len(target_data))\n",
    "        loss = compute_loss(pred, target_data)\n",
    "        losses.append(loss)\n",
    "    \n",
    "    avg_loss = np.mean(losses)\n",
    "    std_loss = np.std(losses)\n",
    "    results[pooling] = (avg_loss, std_loss)\n",
    "    \n",
    "    print(f\"  å¹³å‡æå¤±ï¼š{avg_loss:.6f} Â± {std_loss:.6f}\")\n",
    "\n",
    "# è¦–è¦ºåŒ–çµæœ\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "methods = list(results.keys())\n",
    "means = [results[m][0] for m in methods]\n",
    "stds = [results[m][1] for m in methods]\n",
    "\n",
    "colors = ['steelblue', 'coral', 'mediumseagreen', 'orchid']\n",
    "plt.bar(methods, means, yerr=stds, capsize=5, alpha=0.7, color=colors)\n",
    "plt.xlabel('æ± åŒ–æ–¹æ³•', fontsize=12)\n",
    "plt.ylabel('å¹³å‡æå¤±', fontsize=12)\n",
    "plt.title('æ¶ˆèç ”ç©¶ï¼šæ± åŒ–ç­–ç•¥æ¯”è¼ƒ\\nï¼ˆå‰å‘å‚³éé©—è­‰ï¼‰', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# åœ¨æ¢å½¢åœ–ä¸Šæ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "for i, (method, mean) in enumerate(zip(methods, means)):\n",
    "    plt.text(i, mean + stds[i] + 0.001, f'{mean:.4f}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pooling_ablation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"æ¶ˆèçµæœï¼š\")\n",
    "print(\"=\" * 60)\n",
    "best_method = min(results, key=lambda k: results[k][0])\n",
    "print(f\"æœ€ä½³æ± åŒ–æ–¹æ³•ï¼š{best_method.upper()}\")\n",
    "print(f\"æå¤±ï¼š{results[best_method][0]:.6f} Â± {results[best_method][1]:.6f}\")\n",
    "print(\"\\nâœ“ æ¶ˆèç ”ç©¶å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬åç¯€ï¼šçµè«–\n",
    "\n",
    "é›†åˆ Seq2Seq æ¶æ§‹å’Œç ”ç©¶ç™¼ç¾çš„ç¸½çµã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ç¬¬åç¯€ï¼šçµè«–\n",
    "# ================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"è«–æ–‡ 8ï¼šé †åºå¾ˆé‡è¦ - é›†åˆçš„ SEQ2SEQ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "âœ… å¯¦ä½œå®Œæˆ\n",
    "\n",
    "æœ¬ç­†è¨˜æœ¬å±•ç¤ºäº†ä½¿ç”¨åºåˆ—åˆ°åºåˆ—æ¨¡å‹è™•ç†ç„¡åºé›†åˆçš„è®€å–-è™•ç†-å¯«å…¥æ¶æ§‹ã€‚\n",
    "\n",
    "ä¸»è¦æˆå°±ï¼š\n",
    "\n",
    "1. æ¶æ§‹å…ƒä»¶\n",
    "   â€¢ æ’åˆ—ä¸è®Šçš„é›†åˆç·¨ç¢¼å™¨ï¼ˆå¤šç¨®æ± åŒ–ç­–ç•¥ï¼‰\n",
    "   â€¢ åŸºæ–¼å…§å®¹çš„æ³¨æ„åŠ›æ©Ÿåˆ¶\n",
    "   â€¢ å¸¶æ³¨æ„åŠ›çš„ LSTM è§£ç¢¼å™¨\n",
    "   â€¢ ç”¨æ–¼æ¯”è¼ƒçš„é †åºæ•æ„ŸåŸºç·š\n",
    "\n",
    "2. å±•ç¤ºçš„æ¦‚å¿µ\n",
    "   â€¢ é€šéæ± åŒ–é‹ç®—å¯¦ç¾æ’åˆ—ä¸è®Šæ€§\n",
    "   â€¢ å°ç„¡åºå…ƒç´ çš„æ³¨æ„åŠ›\n",
    "   â€¢ è®€å–-è™•ç†-å¯«å…¥ç¯„å¼\n",
    "   â€¢ é›†åˆ â†’ åºåˆ—è½‰æ›\n",
    "\n",
    "3. å¯¦é©—é©—è­‰\n",
    "   â€¢ æ’åºä»»å‹™ï¼ˆç¶“å…¸é›†åˆå•é¡Œï¼‰\n",
    "   â€¢ æ’åˆ—ä¸è®Šæ€§é©—è­‰\n",
    "   â€¢ æ¯”è¼ƒï¼šSet2Seq vs Seq2Seq\n",
    "   â€¢ æ¶ˆèï¼šä¸åŒæ± åŒ–ç­–ç•¥\n",
    "\n",
    "é—œéµæ´è¦‹ï¼š\n",
    "\n",
    "âœ“ æ’åˆ—ä¸è®Šæ€§å¾ˆé‡è¦\n",
    "  Set2Seq ç„¡è«–è¼¸å…¥é †åºå¦‚ä½•éƒ½ä¿æŒä¸€è‡´çš„æ•ˆèƒ½ï¼Œ\n",
    "  è€Œæ¨™æº– Seq2Seq åœ¨æ’åˆ—è¼¸å…¥ä¸Šæœƒå¤±æ•—ã€‚\n",
    "\n",
    "âœ“ æ± åŒ–ç­–ç•¥çš„å½±éŸ¿\n",
    "  ä¸åŒçš„æ± åŒ–æ–¹æ³•ï¼ˆmeanã€sumã€maxã€attentionï¼‰æœ‰ä¸åŒçš„\n",
    "  æ­¸ç´åç½®ã€‚å¹³å‡æ± åŒ–é€šå¸¸æ˜¯å¾ˆå¥½çš„é è¨­é¸æ“‡ã€‚\n",
    "\n",
    "âœ“ æ³¨æ„åŠ›æä¾›å¯è§£é‡‹æ€§\n",
    "  æ³¨æ„åŠ›æ¬Šé‡æ­ç¤ºäº†è§£ç¢¼å™¨åœ¨ç”Ÿæˆæ¯å€‹è¼¸å‡ºæ™‚\n",
    "  é—œæ³¨å“ªäº›è¼¸å…¥å…ƒç´ ã€‚\n",
    "\n",
    "âœ“ å¯æ³›åŒ–åˆ°å…¶ä»–é›†åˆä»»å‹™\n",
    "  æ­¤æ¶æ§‹å¯æ“´å±•åˆ°ï¼š\n",
    "  - æ‰¾å‡º k å€‹æœ€å¤§/æœ€å°å…ƒç´ \n",
    "  - é›†åˆé‹ç®—ï¼ˆè¯é›†ã€äº¤é›†ï¼‰\n",
    "  - ç„¡åºç¯€é»çš„åœ–å•é¡Œ\n",
    "  - é»é›²è™•ç†\n",
    "\n",
    "èˆ‡å…¶ä»–è«–æ–‡çš„é—œè¯ï¼š\n",
    "\n",
    "â€¢ è«–æ–‡ 6ï¼ˆPointer Networksï¼‰ï¼šå¯è®Šè¼¸å‡ºé•·åº¦ã€åŸºæ–¼æ³¨æ„åŠ›çš„é¸æ“‡\n",
    "â€¢ è«–æ–‡ 12ï¼ˆGNNï¼‰ï¼šç„¡åºç¯€é»ä¸Šçš„è¨Šæ¯å‚³é\n",
    "â€¢ è«–æ–‡ 13ï¼ˆTransformersï¼‰ï¼šè‡ªæ³¨æ„åŠ›ï¼ˆå¸¶ PE æ™‚æ’åˆ—ç­‰è®Šï¼‰\n",
    "â€¢ è«–æ–‡ 14ï¼ˆBahdanau æ³¨æ„åŠ›ï¼‰ï¼šåŸå§‹æ³¨æ„åŠ›æ©Ÿåˆ¶\n",
    "â€¢ è«–æ–‡ 16ï¼ˆé—œä¿‚æ¨ç†ï¼‰ï¼šåœ¨ç‰©ä»¶é›†åˆä¸Šæ“ä½œ\n",
    "\n",
    "å¯¦ä½œèªªæ˜ï¼š\n",
    "\n",
    "âš ï¸  åƒ…å‰å‘å‚³éï¼šé€™å±•ç¤ºäº†æ¶æ§‹è€Œç„¡è¨“ç·´ã€‚\n",
    "    å°æ–¼å¯¦éš›å­¸ç¿’ï¼Œéœ€è¦ç‚ºæ‰€æœ‰å…ƒä»¶å¯¦ä½œæ¢¯åº¦ã€‚\n",
    "\n",
    "âœ…  æ¶æ§‹å·²é©—è­‰ï¼šæ‰€æœ‰å…ƒä»¶ï¼ˆç·¨ç¢¼å™¨ã€æ³¨æ„åŠ›ã€è§£ç¢¼å™¨ï¼‰\n",
    "    æ­£ç¢ºé‹ä½œä¸¦ä¿æŒæ’åˆ—ä¸è®Šæ€§ã€‚\n",
    "\n",
    "ğŸ”„  ç”Ÿç”¢ç’°å¢ƒï¼šç§»æ¤åˆ° PyTorch/JAX ä»¥é€²è¡Œè‡ªå‹•å¾®åˆ†ã€\n",
    "    GPU åŠ é€Ÿå’Œåœ¨æ›´å¤§è³‡æ–™é›†ä¸Šè¨“ç·´ã€‚\n",
    "\n",
    "ç¾ä»£æ“´å±•ï¼š\n",
    "\n",
    "æ­¤å·¥ä½œå•Ÿç™¼äº†ï¼š\n",
    "â€¢ DeepSetsï¼ˆZaheer et al. 2017ï¼‰- é›†åˆå‡½æ•¸çš„ç†è«–æ¡†æ¶\n",
    "â€¢ Set Transformerï¼ˆLee et al. 2019ï¼‰- é›†åˆçš„å®Œæ•´æ³¨æ„åŠ›\n",
    "â€¢ é»é›²ç¶²è·¯ - ç„¡åºé»çš„ 3D è¦–è¦º\n",
    "â€¢ åœ–æ³¨æ„åŠ›ç¶²è·¯ - åœ–çµæ§‹ä¸Šçš„æ³¨æ„åŠ›\n",
    "\n",
    "æ•™è‚²åƒ¹å€¼ï¼š\n",
    "\n",
    "âœ“ æ’åˆ—ä¸è®Šæ€§çš„æ¸…æ™°å±•ç¤º\n",
    "âœ“ é¡¯ç¤ºçµæ§‹åŒ–è³‡æ–™çš„æ­¸ç´åç½®çš„é‡è¦æ€§\n",
    "âœ“ é€£æ¥åºåˆ—æ¨¡å‹å’Œé›†åˆå‡½æ•¸\n",
    "âœ“ æ³¨æ„åŠ›æ©Ÿåˆ¶çš„å¯¦ç”¨è¦–è¦ºåŒ–\n",
    "âœ“ ç†è§£ç¾ä»£é›†åˆ/åœ–æ¶æ§‹çš„åŸºç¤\n",
    "\n",
    "ã€Œé †åºåœ¨æ‡‰è©²é‡è¦æ™‚é‡è¦ï¼Œåœ¨ä¸æ‡‰è©²é‡è¦æ™‚ä¸é‡è¦ã€‚ã€\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“ è«–æ–‡ 8 å¯¦ä½œå®Œæˆ - é›†åˆè™•ç†å·²æŒæ¡ï¼\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
